{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование предобученных моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv\n",
    "import time\n",
    "import dataclasses\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from hse_slr.models.utils import SLInference, make_prediction\n",
    "from hse_slr.draw_landmarks import draw_landmarks_on_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование моделей из mediapipe для извлечения признаков на основе видео.\n",
    "\n",
    "Процесс:\n",
    "1. Создает цикл для чтения кадров из видео\n",
    "2. Внутри цикла с каждого кадра происходит применение предобученной модели\n",
    "3. Признаки сохраняются в словарь, а далее их можно сохранить в json\n",
    "\n",
    "Модели:\n",
    "1. [HandLandmarker](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker)\n",
    "2. [PoseLandmarker](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение признаков рук"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Точки на руках](images/hand-landmarks.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего извлекается 21 точка, по 4 точки на каждый палецб и одна точка, показывающая начало запястья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd()).parent / 'data'\n",
    "model_path = data_path / 'hand_landmarker.task'\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "HandLandmarkerResult = mp.tasks.vision.HandLandmarkerResult\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    num_hands=2,\n",
    "    min_hand_detection_confidence = 0.1,\n",
    "    min_hand_presence_confidence = 0.1,\n",
    "    min_tracking_confidence = 0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извелечение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1709581094.488610       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(str(data_path / 'raw' / 'train' / '0a04c0f6-48e0-43d5-9e64-d106441cab9e.mp4'))\n",
    "frames = []\n",
    "\n",
    "with HandLandmarker.create_from_options(options) as landmarker:\n",
    "\n",
    "    hand_landmarker_results = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "\n",
    "        hand_landmarker_result = landmarker.detect_for_video(mp_image, int(time.time() * 1000))\n",
    "\n",
    "        frames.append(mp_image)\n",
    "        hand_landmarker_results.append(dataclasses.asdict(hand_landmarker_result))\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация разметки рук"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_hands_landmarks(frame=0):\n",
    "    plt.imshow(\n",
    "        cv.cvtColor(\n",
    "            draw_landmarks_on_image(\n",
    "                frames[frame].numpy_view(),\n",
    "                hand_landmarker_results[frame],\n",
    "                landmark_type='hand'\n",
    "            ),\n",
    "            cv.COLOR_BGR2RGB)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0a06b308ad42a2a3160424c169d04f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame', max=47), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interact(\n",
    "    show_hands_landmarks,\n",
    "    frame=(0, len(hand_landmarker_results) - 1, 1)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение признаков поз"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"images/pose_landmarks_index.png\" width=\"350\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всего извлекается 32 точки: \n",
    "* 11 точек с лица\n",
    "* 12 точек с рук - по 6 с каждой: плечи, локти, запястья, и кисти\n",
    "* 10 точек с ног - по 5 с каждой: бедра, колени, лодыжки и стопы\n",
    "\n",
    "[Полный список с названиями](https://developers.google.com/mediapipe/solutions/vision/pose_landmarker#pose_landmarker_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getcwd()).parent / 'data'\n",
    "model_path = data_path / 'pose_landmarker_heavy.task'\n",
    "\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    num_poses = 1,\n",
    "    running_mode=VisionRunningMode.VIDEO,\n",
    "    min_pose_detection_confidence = 0.3,\n",
    "    min_tracking_confidence = 0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Извлечение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1709581095.914157       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M3 Pro\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't receive frame (stream end?). Exiting ...\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(str(data_path / 'raw' / 'train' / '0a04c0f6-48e0-43d5-9e64-d106441cab9e.mp4'))\n",
    "frames = []\n",
    "\n",
    "with PoseLandmarker.create_from_options(options) as landmarker:\n",
    "\n",
    "    pose_landmarker_results = []\n",
    "\n",
    "    while True:\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "            break\n",
    "\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "\n",
    "        pose_landmarker_result = landmarker.detect_for_video(mp_image, int(time.time() * 1000))\n",
    "\n",
    "        frames.append(mp_image)\n",
    "        pose_landmarker_results.append(dataclasses.asdict(pose_landmarker_result))\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Визуализация разметки позы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pose_landmarks(frame=0):\n",
    "    plt.imshow(\n",
    "        cv.cvtColor(\n",
    "            draw_landmarks_on_image(\n",
    "                frames[frame].numpy_view(),\n",
    "                pose_landmarker_results[frame],\n",
    "                landmark_type='pose'\n",
    "            ),\n",
    "            cv.COLOR_BGR2RGB)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1295e3ae4d342deb233531d790234c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='frame', max=47), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interact(\n",
    "    show_pose_landmarks,\n",
    "    frame=(0, len(pose_landmarker_results) - 1, 1)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация жестов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование предобученной модели [EasySign](https://github.com/ai-forever/easy_sign/tree/main) для распознования РЖЯ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = Path(os.getcwd()).absolute().parent / 'hse_slr/models/configs/config.json'\n",
    "\n",
    "inference_thread = SLInference(CONFIG_PATH)\n",
    "inference_thread.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Использование модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Завершение чтения видео.\n"
     ]
    }
   ],
   "source": [
    "res = make_prediction(\n",
    "    inference_thread,\n",
    "    str(data_path / 'raw' / 'test' / '0a4da017-349b-4457-9f2a-930978ff5950.mp4')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат классификации: привет \n"
     ]
    }
   ],
   "source": [
    "print(f'Результат классификации: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Итоги\n",
    "1. Посмотрели работу предобученных моделей для извлечения признаков. Далее эти признаки можно использовать для улучшения качества классификатора РЖЯ.\n",
    "2. Посмотрели работу предобученной модель EasySign для классификации РЖЯ.\n",
    "\n",
    "На текущий момент можно использовать эти модели для реализации MVP сервиса распознавания РЖЯ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
